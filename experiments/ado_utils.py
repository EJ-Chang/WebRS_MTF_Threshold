"""
ado_utils.py

å®Œæ•´çš„ ADO (Adaptive Design Optimization) å·¥å…·å‡½æ•¸

æä¾› ADO å¯¦é©—æ‰€éœ€çš„æ ¸å¿ƒåŠŸèƒ½ï¼ŒåŒ…æ‹¬æ•ˆç”¨å‡½æ•¸è¨ˆç®—ã€è²è‘‰æ–¯æ›´æ–°ã€
æ”¶æ–‚æª¢æŸ¥ã€æœ€ä½³è¨­è¨ˆé¸æ“‡ç­‰åŠŸèƒ½ã€‚

Author: EJ  
Last reviewed: 2025-06
"""

import numpy as np
import logging
from typing import Tuple, Optional, Dict, Any, List
from scipy.stats import entropy

# è¨­å®šæ—¥èªŒ
logger = logging.getLogger(__name__)


class ADOEngine:
    """ADO å¼•æ“é¡åˆ¥ï¼Œè™•ç†å¿ƒç†è¨ˆé‡å‡½æ•¸çš„é©æ‡‰æ€§å¯¦é©—è¨­è¨ˆ"""
    
    def __init__(self, 
                 design_space: np.ndarray = None,
                 threshold_range: Tuple[float, float] = (10, 99),
                 slope_range: Tuple[float, float] = (0.1, 3.0),
                 threshold_points: int = 41,
                 slope_points: int = 30):
        """åˆå§‹åŒ– ADO å¼•æ“
        
        Args:
            design_space: è¨­è¨ˆç©ºé–“ï¼ˆMTF å€¼ï¼‰
            threshold_range: é–¾å€¼åƒæ•¸ç¯„åœ
            slope_range: æ–œç‡åƒæ•¸ç¯„åœ  
            threshold_points: é–¾å€¼ç¶²æ ¼é»æ•¸
            slope_points: æ–œç‡ç¶²æ ¼é»æ•¸
        """
        
        # è¨­è¨ˆç©ºé–“ï¼šå¯é¸çš„ MTF å€¼
        if design_space is None:
            self.design_space = np.arange(1, 100, 1)  # 1% åˆ° 99%ï¼Œæ¯ 1% ä¸€æ­¥
        else:
            self.design_space = np.array(design_space)
        
        # åƒæ•¸ç¶²æ ¼
        self.threshold_grid = np.linspace(threshold_range[0], threshold_range[1], threshold_points)
        self.slope_grid = np.linspace(slope_range[0], slope_range[1], slope_points)
        
        # å»ºç«‹ 2D åƒæ•¸ç¶²æ ¼
        self.threshold_mesh, self.slope_mesh = np.meshgrid(self.threshold_grid, self.slope_grid)
        self.param_shape = self.threshold_mesh.shape
        
        # åˆå§‹åŒ–å…ˆé©—åˆ†å¸ƒï¼ˆå‡å‹»åˆ†å¸ƒï¼‰
        self.prior = np.ones(self.param_shape) / np.prod(self.param_shape)
        self.posterior = self.prior.copy()
        
        # è¨˜éŒ„å¯¦é©—æ­·å²
        self.trial_history = []
        self.response_history = []
        
        logger.info(f"ADO å¼•æ“åˆå§‹åŒ–å®Œæˆï¼š{len(self.design_space)} å€‹è¨­è¨ˆé»ï¼Œ{np.prod(self.param_shape)} å€‹åƒæ•¸çµ„åˆ")
    
    
    def logistic_psychometric(self, mtf: float, threshold: float, slope: float) -> float:
        """å¿ƒç†è¨ˆé‡å‡½æ•¸ (Logistic)
        
        Args:
            mtf: MTF åˆºæ¿€å€¼ (%)
            threshold: é–¾å€¼åƒæ•¸
            slope: æ–œç‡åƒæ•¸
            
        Returns:
            åæ‡‰æ©Ÿç‡ (0-1)
        """
        try:
            z = slope * (mtf - threshold)
            # æ•¸å€¼ç©©å®šæ€§è™•ç†
            z = np.clip(z, -700, 700)
            return 1.0 / (1.0 + np.exp(-z))
        except:
            return 0.5
    
    
    def calculate_likelihood(self, mtf: float, response: int) -> np.ndarray:
        """è¨ˆç®—çµ¦å®š MTF å’Œåæ‡‰çš„ä¼¼ç„¶å‡½æ•¸
        
        Args:
            mtf: MTF å€¼
            response: åæ‡‰ (0 æˆ– 1)
            
        Returns:
            likelihood: ä¼¼ç„¶å‡½æ•¸é™£åˆ—
        """
        # è¨ˆç®—æ¯å€‹åƒæ•¸çµ„åˆçš„é æ¸¬æ©Ÿç‡
        prob_matrix = np.zeros(self.param_shape)
        
        for i in range(self.param_shape[0]):
            for j in range(self.param_shape[1]):
                threshold = self.threshold_mesh[i, j]
                slope = self.slope_mesh[i, j]
                prob = self.logistic_psychometric(mtf, threshold, slope)
                
                # è¨ˆç®—ä¼¼ç„¶ï¼šP(response|parameters)
                if response == 1:
                    prob_matrix[i, j] = prob
                else:
                    prob_matrix[i, j] = 1 - prob
        
        return prob_matrix
    
    
    def calculate_mutual_information(self, mtf: float) -> float:
        """è¨ˆç®—çµ¦å®š MTF å€¼çš„äº’è³‡è¨Š
        
        Args:
            mtf: å€™é¸ MTF å€¼
            
        Returns:
            mutual_information: äº’è³‡è¨Šå€¼
        """
        # è¨ˆç®—æ¯å€‹åƒæ•¸çµ„åˆçš„é æ¸¬æ©Ÿç‡
        prob_yes_given_params = np.zeros(self.param_shape)
        
        for i in range(self.param_shape[0]):
            for j in range(self.param_shape[1]):
                threshold = self.threshold_mesh[i, j]
                slope = self.slope_mesh[i, j]
                prob_yes_given_params[i, j] = self.logistic_psychometric(mtf, threshold, slope)
        
        # è¨ˆç®—é‚Šéš›æ©Ÿç‡ï¼šP(response=1|mtf)
        prob_yes_marginal = np.sum(self.posterior * prob_yes_given_params)
        prob_no_marginal = 1 - prob_yes_marginal
        
        # é¿å… log(0)
        prob_yes_marginal = np.clip(prob_yes_marginal, 1e-10, 1-1e-10)
        prob_no_marginal = np.clip(prob_no_marginal, 1e-10, 1-1e-10)
        
        # è¨ˆç®—äº’è³‡è¨Šçš„å…©å€‹åˆ†é‡
        mi_yes = 0
        mi_no = 0
        
        # å°æ–¼ response=1 çš„æƒ…æ³
        likelihood_yes = self.calculate_likelihood(mtf, 1)
        posterior_given_yes = self.posterior * likelihood_yes
        norm_yes = np.sum(posterior_given_yes)
        if norm_yes > 0:
            posterior_given_yes /= norm_yes  # æ­£è¦åŒ–
            
            # KL æ•£åº¦ï¼šD(P(Î¸|y=1,x) || P(Î¸)) - æ•¸å€¼ç©©å®šç‰ˆæœ¬
            # åªè¨ˆç®— posterior > 0 çš„éƒ¨åˆ†
            valid_mask = (posterior_given_yes > 1e-10) & (self.posterior > 1e-10)
            if np.any(valid_mask):
                kl_yes = np.sum(posterior_given_yes[valid_mask] * 
                               np.log(posterior_given_yes[valid_mask] / self.posterior[valid_mask]))
                mi_yes = prob_yes_marginal * kl_yes
        
        # å°æ–¼ response=0 çš„æƒ…æ³
        likelihood_no = self.calculate_likelihood(mtf, 0)
        posterior_given_no = self.posterior * likelihood_no
        norm_no = np.sum(posterior_given_no)
        if norm_no > 0:
            posterior_given_no /= norm_no  # æ­£è¦åŒ–
            
            # KL æ•£åº¦ï¼šD(P(Î¸|y=0,x) || P(Î¸)) - æ•¸å€¼ç©©å®šç‰ˆæœ¬
            valid_mask = (posterior_given_no > 1e-10) & (self.posterior > 1e-10)
            if np.any(valid_mask):
                kl_no = np.sum(posterior_given_no[valid_mask] * 
                              np.log(posterior_given_no[valid_mask] / self.posterior[valid_mask]))
                mi_no = prob_no_marginal * kl_no
        
        return mi_yes + mi_no
    
    
    def get_optimal_design(self) -> float:
        """é¸æ“‡æœ€ä½³çš„ MTF å€¼
        
        Returns:
            optimal_mtf: æœ€ä½³ MTF å€¼
        """
        utilities = []
        
        for mtf in self.design_space:
            utility = self.calculate_mutual_information(mtf)
            utilities.append(utility)
        
        utilities = np.array(utilities)
        optimal_idx = np.argmax(utilities)
        optimal_mtf = self.design_space[optimal_idx]
        
        # é™¤éŒ¯è¼¸å‡º - é¡¯ç¤ºADOæ±ºç­–éç¨‹
        top_5_indices = np.argsort(utilities)[-5:][::-1]  # å–å‰5å
        print(f"ğŸ¯ ADOæ±ºç­– (è©¦æ¬¡ {len(self.trial_history)+1}):")
        for i, idx in enumerate(top_5_indices):
            marker = "â˜…" if idx == optimal_idx else " "
            print(f"  {marker} MTF {self.design_space[idx]:2.0f}%: utility={utilities[idx]:.4f}")
        
        return float(optimal_mtf)
    
    
    def update_posterior(self, mtf: float, response: int):
        """æ ¹æ“šè§€å¯Ÿçµæœæ›´æ–°å¾Œé©—åˆ†å¸ƒ
        
        Args:
            mtf: ä½¿ç”¨çš„ MTF å€¼
            response: è§€å¯Ÿåˆ°çš„åæ‡‰ (0 æˆ– 1)
        """
        # è¨ˆç®—ä¼¼ç„¶å‡½æ•¸
        likelihood = self.calculate_likelihood(mtf, response)
        
        # è²è‘‰æ–¯æ›´æ–°ï¼šposterior âˆ prior Ã— likelihood
        self.posterior = self.posterior * likelihood
        
        # æ­£è¦åŒ–
        self.posterior = normalize_posterior(self.posterior)
        
        # è¨˜éŒ„æ­·å²
        self.trial_history.append(mtf)
        self.response_history.append(response)
        
        logger.info(f"æ›´æ–°å¾Œé©—åˆ†å¸ƒï¼šMTF={mtf}, åæ‡‰={response}")
    
    
    def get_parameter_estimates(self) -> Dict[str, float]:
        """å–å¾—ç›®å‰çš„åƒæ•¸ä¼°è¨ˆ
        
        Returns:
            estimates: åŒ…å«å‡å€¼å’Œæ¨™æº–å·®çš„å­—å…¸
        """
        # è¨ˆç®—æœŸæœ›å€¼
        threshold_mean = np.sum(self.posterior * self.threshold_mesh)
        slope_mean = np.sum(self.posterior * self.slope_mesh)
        
        # è¨ˆç®—è®Šç•°æ•¸å’Œæ¨™æº–å·®
        threshold_var = np.sum(self.posterior * (self.threshold_mesh - threshold_mean)**2)
        slope_var = np.sum(self.posterior * (self.slope_mesh - slope_mean)**2)
        
        threshold_sd = np.sqrt(threshold_var)
        slope_sd = np.sqrt(slope_var)
        
        return {
            'threshold_mean': threshold_mean,
            'threshold_sd': threshold_sd,
            'slope_mean': slope_mean,
            'slope_sd': slope_sd
        }
    
    
    def check_convergence(self, min_trials: int = 15, 
                         threshold_convergence: float = 5.0,
                         slope_convergence: float = 0.3) -> bool:
        """æª¢æŸ¥åƒæ•¸ä¼°è¨ˆæ˜¯å¦æ”¶æ–‚
        
        Args:
            min_trials: æœ€å°‘è©¦é©—æ¬¡æ•¸
            threshold_convergence: é–¾å€¼æ”¶æ–‚æ¨™æº–ï¼ˆæ¨™æº–å·®ï¼‰
            slope_convergence: æ–œç‡æ”¶æ–‚æ¨™æº–ï¼ˆæ¨™æº–å·®ï¼‰
            
        Returns:
            converged: æ˜¯å¦æ”¶æ–‚
        """
        if len(self.trial_history) < min_trials:
            return False
        
        estimates = self.get_parameter_estimates()
        
        threshold_converged = estimates['threshold_sd'] < threshold_convergence
        slope_converged = estimates['slope_sd'] < slope_convergence
        
        return threshold_converged and slope_converged
    
    
    def get_trial_summary(self) -> Dict[str, Any]:
        """å–å¾—ç›®å‰è©¦é©—çš„æ‘˜è¦è³‡è¨Š
        
        Returns:
            summary: è©¦é©—æ‘˜è¦
        """
        estimates = self.get_parameter_estimates()
        converged = self.check_convergence()
        
        return {
            'trial_count': len(self.trial_history),
            'converged': converged,
            **estimates
        }


def safe_log(x: np.ndarray, epsilon: float = 1e-10) -> np.ndarray:
    """æ•¸å€¼ç©©å®šçš„å°æ•¸å‡½æ•¸
    
    Args:
        x: è¼¸å…¥é™£åˆ—
        epsilon: æœ€å°å€¼ï¼Œé¿å… log(0)
        
    Returns:
        å°æ•¸å€¼
    """
    return np.log(np.clip(x, epsilon, 1.0 - epsilon))


def normalize_posterior(posterior: np.ndarray) -> np.ndarray:
    """æ­£è¦åŒ–å¾Œé©—åˆ†å¸ƒ
    
    Args:
        posterior: æœªæ­£è¦åŒ–çš„å¾Œé©—åˆ†å¸ƒ
        
    Returns:
        æ­£è¦åŒ–å¾Œçš„å¾Œé©—åˆ†å¸ƒ
    """
    total = np.sum(posterior)
    if total == 0 or not np.isfinite(total):
        logger.warning("å¾Œé©—åˆ†å¸ƒç¸½å’Œç„¡æ•ˆï¼Œè¿”å›å‡å‹»åˆ†å¸ƒ")
        return np.ones_like(posterior) / np.prod(posterior.shape)
    return posterior / total


if __name__ == "__main__":
    """æ¸¬è©¦ ADO å¼•æ“"""
    
    print("æ¸¬è©¦ ADO å¼•æ“...")
    
    # åˆå§‹åŒ–å¼•æ“
    engine = ADOEngine()
    
    # æ¨¡æ“¬å¹¾å€‹è©¦é©—
    print("\næ¨¡æ“¬è©¦é©—...")
    true_threshold = 50.0
    true_slope = 1.5
    
    for trial in range(10):
        # å–å¾—æœ€ä½³è¨­è¨ˆ
        optimal_mtf = engine.get_optimal_design()
        
        # æ¨¡æ“¬åæ‡‰ï¼ˆåŸºæ–¼çœŸå¯¦åƒæ•¸ï¼‰
        true_prob = engine.logistic_psychometric(optimal_mtf, true_threshold, true_slope)
        response = 1 if np.random.rand() < true_prob else 0
        
        # æ›´æ–°å¼•æ“
        engine.update_posterior(optimal_mtf, response)
        
        # å–å¾—ä¼°è¨ˆ
        estimates = engine.get_parameter_estimates()
        summary = engine.get_trial_summary()
        
        print(f"è©¦é©— {trial+1}: MTF={optimal_mtf:.1f}, åæ‡‰={response}, "
              f"é–¾å€¼ä¼°è¨ˆ={estimates['threshold_mean']:.1f}Â±{estimates['threshold_sd']:.1f}, "
              f"æ”¶æ–‚={summary['converged']}")
    
    print("\nâœ“ ADO å¼•æ“æ¸¬è©¦å®Œæˆ")
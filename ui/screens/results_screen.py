"""
Results screen for WebRS MTF Threshold experiment.
"""
import streamlit as st
import pandas as pd
from ui.components.progress_indicators import show_completion_celebration
from ui.components.response_buttons import create_action_button, create_reset_button
from utils.helpers import format_percentage, format_time_duration
from utils.logger import get_logger

logger = get_logger(__name__)

def display_results_screen(session_manager) -> None:
    """
    Display experiment results
    
    Args:
        session_manager: SessionStateManager instance
    """
    try:
        # Show completion celebration
        show_completion_celebration()
        
        st.header("ğŸ“Š å¯¦é©—çµæœ")
        
        # Get experiment summary
        summary = st.session_state.get('experiment_summary', {})
        trial_results = session_manager.get_trial_results()
        
        if not trial_results:
            st.warning("æ²’æœ‰æ‰¾åˆ°å¯¦é©—æ•¸æ“š")
            _show_navigation_options(session_manager)
            return
        
        # Display summary statistics
        _display_summary_statistics(summary, trial_results)
        
        # Display detailed results
        _display_detailed_results(trial_results)
        
        # Display psychometric function if possible
        _display_psychometric_function(trial_results)
        
        # Download options
        _display_download_options(trial_results, session_manager.get_participant_id())
        
        # Navigation options
        _show_navigation_options(session_manager)
        
    except Exception as e:
        logger.error(f"Error in results screen: {e}")
        st.error(f"Error displaying results: {e}")

def _display_summary_statistics(summary, trial_results):
    """Display summary statistics"""
    st.subheader("ğŸ“ˆ å¯¦é©—çµ±è¨ˆ")
    
    # Calculate statistics from trial results
    total_trials = len(trial_results)
    clear_responses = sum(1 for r in trial_results if r.get('response') == 'clear')
    clear_rate = clear_responses / total_trials if total_trials > 0 else 0
    
    reaction_times = [r.get('reaction_time', 0) for r in trial_results if r.get('reaction_time')]
    avg_reaction_time = sum(reaction_times) / len(reaction_times) if reaction_times else 0
    
    # Display metrics
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("ç¸½è©¦é©—æ•¸", total_trials)
    
    with col2:
        st.metric("ã€Œæ¸…æ¥šã€å›æ‡‰", clear_responses)
    
    with col3:
        st.metric("æ¸…æ¥šç‡", format_percentage(clear_rate))
    
    with col4:
        st.metric("å¹³å‡åæ‡‰æ™‚é–“", format_time_duration(avg_reaction_time))

def _display_detailed_results(trial_results):
    """Display detailed trial results"""
    st.subheader("ğŸ“‹ è©³ç´°çµæœ")
    
    # Convert to DataFrame for better display
    df = pd.DataFrame(trial_results)
    
    if not df.empty:
        # Select relevant columns for display
        display_columns = [
            'trial_number', 'mtf_value', 'response', 'reaction_time', 'timestamp'
        ]
        
        # Only include columns that exist
        available_columns = [col for col in display_columns if col in df.columns]
        
        if available_columns:
            display_df = df[available_columns].copy()
            
            # Format columns for better display
            if 'reaction_time' in display_df.columns:
                display_df['reaction_time'] = display_df['reaction_time'].apply(
                    lambda x: f"{x:.3f}s" if x else "N/A"
                )
            
            if 'mtf_value' in display_df.columns:
                display_df['mtf_value'] = display_df['mtf_value'].apply(
                    lambda x: f"{x:.1f}" if x else "N/A"
                )
            
            if 'response' in display_df.columns:
                display_df['response'] = display_df['response'].apply(
                    lambda x: "æ¸…æ¥š" if x == "clear" else "ä¸æ¸…æ¥š" if x == "not_clear" else x
                )
            
            # Rename columns for Chinese display
            column_names = {
                'trial_number': 'è©¦é©—ç·¨è™Ÿ',
                'mtf_value': 'MTF å€¼',
                'response': 'å›æ‡‰',
                'reaction_time': 'åæ‡‰æ™‚é–“',
                'timestamp': 'æ™‚é–“æˆ³è¨˜'
            }
            
            display_df = display_df.rename(columns=column_names)
            
            st.dataframe(display_df, use_container_width=True)
        else:
            st.warning("ç„¡æ³•é¡¯ç¤ºè©³ç´°çµæœï¼šç¼ºå°‘å¿…è¦çš„æ•¸æ“šæ¬„ä½")

def _display_psychometric_function(trial_results):
    """Display psychometric function if possible"""
    try:
        import plotly.graph_objects as go
        import numpy as np
        
        st.subheader("ğŸ“ˆ å¿ƒç†æ¸¬é‡å‡½æ•¸")
        
        # Extract MTF values and responses
        mtf_values = []
        responses = []
        
        for result in trial_results:
            mtf_val = result.get('mtf_value')
            response = result.get('response')
            
            if mtf_val is not None and response is not None:
                mtf_values.append(mtf_val)
                responses.append(1 if response == 'clear' else 0)
        
        if len(mtf_values) < 5:
            st.info("æ•¸æ“šé»ä¸è¶³ï¼Œç„¡æ³•ç¹ªè£½å¿ƒç†æ¸¬é‡å‡½æ•¸ï¼ˆéœ€è¦è‡³å°‘ 5 å€‹æ•¸æ“šé»ï¼‰")
            return
        
        # Create binned data for plotting
        unique_mtf = sorted(set(mtf_values))
        if len(unique_mtf) < 3:
            st.info("MTF å€¼è®ŠåŒ–ç¯„åœå¤ªå°ï¼Œç„¡æ³•ç¹ªè£½æœ‰æ„ç¾©çš„å¿ƒç†æ¸¬é‡å‡½æ•¸")
            return
        
        # Calculate proportion correct for each MTF value
        mtf_bins = []
        proportions = []
        counts = []
        
        for mtf in unique_mtf:
            indices = [i for i, x in enumerate(mtf_values) if x == mtf]
            if indices:
                responses_for_mtf = [responses[i] for i in indices]
                proportion = sum(responses_for_mtf) / len(responses_for_mtf)
                mtf_bins.append(mtf)
                proportions.append(proportion)
                counts.append(len(responses_for_mtf))
        
        # Create plot
        fig = go.Figure()
        
        # Add data points
        fig.add_trace(go.Scatter(
            x=mtf_bins,
            y=proportions,
            mode='markers+lines',
            marker=dict(size=8, color='blue'),
            line=dict(color='blue', width=2),
            name='è§€å¯Ÿæ•¸æ“š',
            text=[f"n={count}" for count in counts],
            hovertemplate='MTF: %{x:.1f}<br>æ¸…æ¥šç‡: %{y:.1%}<br>%{text}<extra></extra>'
        ))
        
        # Update layout
        fig.update_layout(
            title="å¿ƒç†æ¸¬é‡å‡½æ•¸",
            xaxis_title="MTF å€¼",
            yaxis_title="ã€Œæ¸…æ¥šã€å›æ‡‰æ¯”ä¾‹",
            yaxis=dict(range=[0, 1], tickformat='.0%'),
            showlegend=True,
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
        
        # Show interpretation
        with st.expander("ğŸ“– çµæœè§£é‡‹"):
            st.markdown("""
            **å¿ƒç†æ¸¬é‡å‡½æ•¸èªªæ˜ï¼š**
            - X è»¸ï¼šMTF å€¼ï¼ˆèª¿åˆ¶å‚³éå‡½æ•¸å€¼ï¼Œè¶Šé«˜è¡¨ç¤ºåœ–åƒè¶Šæ¸…æ™°ï¼‰
            - Y è»¸ï¼šå›æ‡‰ã€Œæ¸…æ¥šã€çš„æ¯”ä¾‹
            - ç†æƒ³æƒ…æ³ä¸‹ï¼ŒMTF å€¼è¶Šé«˜ï¼Œå›æ‡‰ã€Œæ¸…æ¥šã€çš„æ¯”ä¾‹æ‡‰è©²è¶Šé«˜
            - å‡½æ•¸çš„é™¡å³­ç¨‹åº¦åæ˜ äº†æ‚¨å°æ¸…æ™°åº¦è®ŠåŒ–çš„æ•æ„Ÿæ€§
            """)
        
    except ImportError:
        st.info("ç„¡æ³•ç¹ªè£½å¿ƒç†æ¸¬é‡å‡½æ•¸ï¼šç¼ºå°‘ plotly åº«")
    except Exception as e:
        logger.warning(f"Error creating psychometric function: {e}")
        st.warning("ç¹ªè£½å¿ƒç†æ¸¬é‡å‡½æ•¸æ™‚ç™¼ç”ŸéŒ¯èª¤")

def _display_download_options(trial_results, participant_id):
    """Display download options for results"""
    st.subheader("ğŸ’¾ ä¸‹è¼‰çµæœ")
    
    try:
        # Convert to DataFrame
        df = pd.DataFrame(trial_results)
        
        if not df.empty:
            # CSV download
            csv_data = df.to_csv(index=False)
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ CSV æ ¼å¼",
                data=csv_data,
                file_name=f"{participant_id}_mtf_results.csv",
                mime="text/csv"
            )
            
            # JSON download
            json_data = df.to_json(orient='records', indent=2)
            st.download_button(
                label="ğŸ“¥ ä¸‹è¼‰ JSON æ ¼å¼",
                data=json_data,
                file_name=f"{participant_id}_mtf_results.json",
                mime="application/json"
            )
        else:
            st.warning("æ²’æœ‰æ•¸æ“šå¯ä¾›ä¸‹è¼‰")
            
    except Exception as e:
        logger.error(f"Error creating download options: {e}")
        st.error("å‰µå»ºä¸‹è¼‰é¸é …æ™‚ç™¼ç”ŸéŒ¯èª¤")

def _show_navigation_options(session_manager):
    """Show navigation options"""
    st.markdown("---")
    st.subheader("ğŸ”„ ä¸‹ä¸€æ­¥")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if create_action_button(
            "é‡æ–°é–‹å§‹å¯¦é©—",
            button_type="secondary",
            key="restart_experiment"
        ):
            if create_reset_button("ç¢ºèªé‡æ–°é–‹å§‹", key_suffix="results"):
                session_manager.reset_experiment()
                st.rerun()
    
    with col2:
        if create_action_button(
            "è¿”å›ä¸»é ",
            button_type="primary",
            key="return_home"
        ):
            session_manager.set_experiment_stage('welcome')
            st.rerun()
    
    with col3:
        if create_action_button(
            "æ•ˆèƒ½æ¸¬è©¦",
            button_type="secondary",
            key="performance_test"
        ):
            session_manager.set_experiment_stage('benchmark')
            st.rerun()